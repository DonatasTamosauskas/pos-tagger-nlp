{"cells":[{"cell_type":"markdown","metadata":{},"source":["# The network:\n","1. CNN character level word embedder\n","1. concatenate CNN embedding with word embedding\n","1. bi-directional LSTM block, looking at a sentence\n","1. fully conncected layer? (what does linear projection mean?)"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[],"source":["# !pip install fastprogress matplotlib\n","import os\n","import math\n","import sys\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from fastprogress import progress_bar, master_bar\n","import matplotlib.pyplot as plt\n","from pathlib import Path\n","import numpy as np\n","\n","KAGGLE = True\n","\n","training_data = Path(\"../input/sents.train\") if KAGGLE else Path(\"../data/sents.train\")"]},{"cell_type":"markdown","metadata":{},"source":["# Creating data input pipeline"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import torch.utils.data\n","from random import uniform\n","\n","\n","class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, path, to_lower=True, training=True, make_unknown=None, letter_emb_len=15, too_long_split=10):\n","        self.to_lower = to_lower\n","        self.training = training\n","        self.make_unknown = make_unknown\n","        self.letter_emb_len = letter_emb_len\n","        self.too_long_split = too_long_split\n","        \n","        self.sentences = []\n","        self.vocab = []\n","        self.tags = []\n","        \n","        self.generate_dataset(path)\n","        self.UNKONWN_WORD = len(self.vocab) + 1\n","        \n","        self.LETTER_MIN = 32\n","        self.LETTER_MAX = 126\n","        self.letter_len = self.LETTER_MAX - self.LETTER_MIN + 2\n","        self.UNKNOWN_LETTER = self.letter_len\n","\n","    def __len__(self):\n","        return len(self.sentences)\n","    \n","    def __getitem__(self, index):\n","        sentence_embs, tag_embs = self.transform_sentence(self.sentences[index])\n","        return sentence_embs, tag_embs\n","    \n","    def generate_dataset(self, path):\n","        with open(path, 'r') as input_file:\n","            self.sentences = input_file.read().split(\"\\n\")\n","            \n","            if len(self.vocab) == 0:\n","                self.create_vocabs(self.sentences)\n","                self.vocab_size = len(self.vocab) + 2 # Unkown words, padding\n","                self.tag_size = len(self.tags) + 1 # Padding\n","            \n","            if self.sentences[-1] == \"\":\n","                self.sentences.pop()\n","    \n","    def create_vocabs(self, sentences):\n","        vocab_set = set()\n","        tag_set = set()\n","\n","        for sentence in sentences:\n","            for word in sentence.split(\" \"):\n","                try:\n","                    word, tag = self.split_words_tag(word)\n","                    vocab_set.add(word.lower() if self.to_lower else word)\n","                    tag_set.add(tag)\n","                except RuntimeError:\n","                    print(\"Not a valid word/tag pair: \" + word)\n","\n","        self.vocab = list(vocab_set)\n","        self.tags = list(tag_set)\n","            \n","    def transform_sentence(self, sentence):\n","        numeric_sent, letter_embs, tags = [], [], []\n","\n","        for word_tag in sentence.split(\" \"):\n","            try:\n","                if self.training:\n","                    word, tag = self.split_words_tag(word_tag)\n","                    tag_id = self.tags.index(tag) + 1\n","                    word_id = self.get_word_id(word)                    \n","                else:\n","                    word = word_tag\n","                    word_id = self.vocab.index(word.lower() if self.to_lower else word) + 1\n","\n","            except RuntimeError:\n","                print(\"Not a valid word/tag pair: \" + word_tag)\n","            except ValueError:\n","#                 print(\"Word not in the vocab: \" + word_tag)\n","                # The id of an unknown word\n","                word_id = self.UNKONWN_WORD\n","\n","            numeric_sent.append(word_id)\n","            letter_embs.append(self.transform_word(word))\n","            if self.training: tags.append(tag_id)\n","\n","        return (torch.tensor(numeric_sent), torch.cat(letter_embs).view(-1, self.letter_emb_len)), torch.tensor(tags) if self.training else []\n","    \n","    def get_word_id(self, word):\n","        # Replacing a random subset of words with the unkown word id\n","        if self.make_unknown is not None:\n","            if uniform(0, 1) < self.make_unknown:\n","                return self.UNKONWN_WORD\n","            else:\n","                return self.vocab.index(word.lower() if self.to_lower else word) + 1\n","        else:\n","            return self.vocab.index(word.lower() if self.to_lower else word) + 1\n","        \n","    def transform_word(self, word):\n","        # 32 -> 126 range\n","        word_len = len(word)\n","        letter_embs = torch.zeros(self.letter_emb_len, dtype=torch.int64)\n","        \n","        if word_len <= self.letter_emb_len:\n","            for i, letter in enumerate(word):\n","                emb = ord(letter)\n","                letter_embs[i] = emb - self.LETTER_MIN + 1 if(emb >= self.LETTER_MIN <= self.LETTER_MAX) else self.UNKNOWN_LETTER\n","        else:\n","            #Word is too long for embedding\n","            for i in range(self.letter_emb_len):\n","                if i <= self.too_long_split:\n","                    letter_embs[i] = ord(word[i]) - self.LETTER_MIN\n","                else:\n","                    letter_embs[i] = ord(word[-(self.letter_emb_len - i)]) - self.LETTER_MIN\n","                    \n","        return letter_embs\n","\n","    @staticmethod\n","    def split_words_tag(word):\n","        words_tag = word.split(\"/\")\n","        \n","        if len(words_tag) < 2: \n","            raise RuntimeError(\"Not a valid word/tag pair:\" + word)\n","            \n","        tag = words_tag.pop()\n","        word = \"/\".join(words_tag)\n","        \n","        return word, tag\n","    \n","    def print_sentence(self, sentence):\n","        print(\" \".join([self.vocab[word.item()] for word in sentence.view(-1)]))\n","                \n","    def decode_sentence(self, sentence):\n","        print(sentence)\n","        answ = [self.vocab[word.item() - 1] for word in sentence.view(-1)]\n","        return answ\n","    \n","    def decode_tags(self, tag_ids):\n","        return [self.tags[tag.item() - 1] for tag in tag_ids.view(-1)]\n","    \n","    def __getstate__(self):\n","        d = dict(self.__dict__)\n","        del d['sentences']\n","        return d\n","    \n","    def __setstate(self, d):\n","        self.__dict__.update(d)\n","        self.__dict__.update({'sentences': []})"]},{"cell_type":"markdown","metadata":{},"source":["## Pad the input so that it is possible to use mini-batches\n","\n","- Padding | https://discuss.pytorch.org/t/understanding-pack-padded-sequence-and-pad-packed-sequence/4099\n","- Padding | https://discuss.pytorch.org/t/simple-working-example-how-to-use-packing-for-variable-length-sequence-inputs-for-rnn/2120\n","\n","## The padding needs to take place in the DataLoader\n","- Most likely will need to use sampler & collate_fn\n"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","\n","def pad_seq(sequences):\n","    x_word, x_let, y = [], [], []\n","    \n","    for (word_embs, letter_embs), targets in sequences:\n","        x_word.append(word_embs)\n","        x_let.append(letter_embs)\n","        y.append(targets)\n","        \n","    return (pad_sequence(x_word, batch_first=True), pad_sequence(x_let, batch_first=True)) , pad_sequence(y, batch_first=True)"]},{"cell_type":"markdown","metadata":{},"source":["# Initial simple model implementation "]},{"cell_type":"markdown","metadata":{},"source":["## Proposed plan:\n","1. Begin with word-level LSTM (check for an example in forum)\n","2. Make it bi-directional\n","3. Add character-level CNN"]},{"cell_type":"markdown","metadata":{},"source":["Try a new notebook: https://polynote.org/docs/01-installation.html"]},{"cell_type":"code","execution_count":36,"metadata":{"trusted":true},"outputs":[],"source":["class LstmCnnTagger(nn.Module):\n","    def __init__(self, word_emb_dim, letter_emb_dim, hidden_dim, word_vocab_size, letter_vocab_size, letter_word_size, tagset_size):\n","        super(LstmCnnTagger, self).__init__()\n","        \n","        self.hidden_dim = hidden_dim\n","        self.letter_word_size = letter_word_size # 15\n","        self.letter_emb_dim = letter_emb_dim\n","        self.word_emb_dim = word_emb_dim\n","\n","        self.word_embeddings = nn.Embedding(word_vocab_size, word_emb_dim)\n","        self.letter_embeddings = nn.Embedding(letter_vocab_size, letter_emb_dim)\n","        \n","        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=23, kernel_size=5)\n","        self.max_pool = nn.MaxPool2d(2,2)\n","        self.cnn2 = nn.Conv2d(in_channels=23, out_channels=word_emb_dim, kernel_size=3)\n","        self.max_pool_last = nn.MaxPool2d(2, 10)\n","\n","        self.lstm = nn.LSTM(word_emb_dim * 2, hidden_dim)        \n","        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n","    \n","    def forward(self, sentence):\n","        words, letters = sentence\n","        batches = words.shape[0]\n","        \n","        word_embeds = self.word_embeddings(words)\n","        letter_embeds = self.letter_embeddings(letters.view(-1, self.letter_word_size))\n","\n","        cnn_feat = self.cnn1(letter_embeds.view(-1, 1, self.letter_word_size, self.letter_emb_dim))\n","        cnn_feat = F.relu(self.max_pool(cnn_feat))\n","        cnn_feat = self.cnn2(cnn_feat)\n","        cnn_feat = F.relu(self.max_pool_last(cnn_feat))\n","            \n","        concat = torch.cat([\n","            cnn_feat.view(len(words[-1]), batches, self.word_emb_dim), \n","            word_embeds.view(len(words[-1]), batches, -1)\n","        ], 2)\n","        \n","        lstm_out, _ = self.lstm(concat)\n","        tag_space = self.hidden2tag(lstm_out.view(len(words[-1]) * batches, -1))\n","        tag_scores = F.log_softmax(tag_space, dim=1)\n","        \n","        return tag_scores"]},{"cell_type":"code","execution_count":29,"metadata":{"trusted":true},"outputs":[],"source":["def train_model(model, data_loader, epochs=1, lr=0.01, patience=10, lr_decrease=2):\n","    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","    print(\"Device: {}\". format(device))\n","\n","    loss_func = nn.NLLLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    tagset_size = data_loader.dataset.tag_size\n","    losses = []\n","    i = 0\n","    \n","    last_min_loss = 10\n","    steps_after_loss = 0\n","\n","    model.to(device)\n","    model.zero_grad()\n","\n","    master = master_bar(range(epochs))\n","    for epoch in master:\n","        for (x1, x2), y in progress_bar(data_loader, parent=master):\n","\n","            model.zero_grad()\n","            x, y = (x1.to(device), x2.to(device)), y.to(device)\n","\n","            pred = model(x)\n","            loss = loss_func(pred.view(-1, tagset_size), y.view(-1))\n","\n","            loss.backward()\n","            optimizer.step()\n","            \n","            if loss.item() < last_min_loss:\n","                last_min_loss = loss.item()\n","                steps_after_loss = 0\n","            elif steps_after_loss > patience:\n","                steps_after_loss = 0\n","                lr = lr / lr_decrease\n","                optimizer = optim.Adam(model.parameters(), lr=lr)\n","                print(\"No decrease in loss for \" + str(patience) + \" steps. Decrementing lr: \" + str(lr))\n","            else:\n","                steps_after_loss += 1\n","\n","            if i % 10 == 0: \n","                losses.append(loss.item())\n","                print(\"Loss: \" + str(loss.item()))\n","            i += 1\n","            \n","    plt.plot(losses)\n","    print(\"Min loss: \" + str(min(losses)))"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["def export_model(model, dataset, train_time):\n","    model_name = str(type(model)).split(\".\")[-1][:-2]\n","    model_save_name = model_name + \"_\" + str(train_time)\n","    \n","    torch.save(model, model_save_name + \"_1.data\")\n","    torch.save(dataset, model_save_name + \"_2.data\")"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","def prepare_dataset_infer(dataset, input_filename):\n","    dataset.generate_dataset(input_filename)\n","    dataset.training = False\n","    return dataset\n","\n","def generate_results(model, dataset, num_workers=0):\n","    cpu = torch.device(\"cpu\")\n","    model.to(cpu)\n","    \n","    dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=num_workers)\n","    preds = []\n","    for i, (x, _) in enumerate(dataloader):\n","        if i % 100 == 0: \n","            print(\"{} | {}\".format(i, len(dataloader.dataset)))\n","            \n","        predictions = model(x)\n","        _, pos_tag_ids = predictions.max(1)\n","\n","        words = dataset.sentences[i].split(\" \")\n","        tags = dataset.decode_tags(pos_tag_ids)\n","        word_tags = [\"/\".join(word_tag) for word_tag in zip(words, tags)]\n","\n","        preds.append(\" \".join(word_tags))\n","    \n","    return preds\n","        \n","def export_preds(preds, filename):\n","    with open(filename, \"w\") as out_file:\n","        out_file.write(\"\\n\".join(preds))\n"]},{"cell_type":"markdown","metadata":{},"source":["# Execution"]},{"cell_type":"code","execution_count":37,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Not a valid word/tag pair: \n"}],"source":["dataset = Dataset(training_data, make_unknown=0.05)\n","\n","num_workers = 2\n","\n","pos_dataloader = DataLoader(\n","    dataset, \n","    batch_size=1, \n","    num_workers=num_workers\n",")\n","\n","pos_dataloader_batched = DataLoader(\n","    dataset,\n","    batch_size=128,\n","    collate_fn=pad_seq,\n","    num_workers=num_workers\n",")"]},{"cell_type":"code","execution_count":38,"metadata":{"trusted":true},"outputs":[],"source":["model_cnn = LstmCnnTagger(\n","    word_emb_dim=256, \n","    letter_emb_dim=30, \n","    hidden_dim=256, \n","    word_vocab_size=dataset.vocab_size, \n","    letter_vocab_size=dataset.letter_len, \n","    letter_word_size=dataset.letter_emb_len, \n","    tagset_size=dataset.tag_size\n",")"]},{"cell_type":"code","execution_count":39,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Device: cuda\n"},{"data":{"text/html":"","text/plain":"<IPython.core.display.HTML object>"},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":"Loss: 3.8083395957946777\nLoss: 0.6660836338996887\nLoss: 0.7792799472808838\nLoss: 0.49007388949394226\nLoss: 0.5908881425857544\nLoss: 0.44627466797828674\nLoss: 0.34107425808906555\nLoss: 0.33643025159835815\nLoss: 0.2935137152671814\nLoss: 0.21591617166996002\nLoss: 0.2338472604751587\nLoss: 0.20052789151668549\nLoss: 0.13216207921504974\nLoss: 0.17689625918865204\nLoss: 0.18714061379432678\nLoss: 0.10605884343385696\nLoss: 0.13266204297542572\nLoss: 0.11665935814380646\nLoss: 0.13153597712516785\nNo decrease in loss for 50 steps. Decrementing lr: 0.005\nLoss: 0.1524566411972046\nLoss: 0.1322701871395111\nLoss: 0.1067795529961586\nLoss: 0.12890398502349854\nLoss: 0.10315176844596863\nLoss: 0.08411089330911636\nNo decrease in loss for 50 steps. Decrementing lr: 0.0025\nLoss: 0.09963709861040115\nLoss: 0.12511323392391205\nLoss: 0.10418090224266052\nLoss: 0.09216538071632385\nLoss: 0.10344715416431427\nLoss: 0.09092838317155838\nLoss: 0.10053832083940506\nMin loss: 0.08411089330911636\n"},{"data":{"image/png":"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\n","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["train_model(model_cnn, pos_dataloader_batched, epochs=2, lr=0.01, patience=70)"]},{"cell_type":"markdown","metadata":{},"source":["## Exporting trained model and built dictionary"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["export_model(model, dataset, 5)"]},{"cell_type":"code","execution_count":40,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"0 | 1993\n100 | 1993\n200 | 1993\n300 | 1993\n400 | 1993\n500 | 1993\n600 | 1993\n700 | 1993\n800 | 1993\n900 | 1993\n1000 | 1993\n1100 | 1993\n1200 | 1993\n1300 | 1993\n1400 | 1993\n1500 | 1993\n1600 | 1993\n1700 | 1993\n1800 | 1993\n1900 | 1993\nAccuracy= 0.930237440429954\n"}],"source":["import copy\n","test_data = Path(\"../input/sents.test\")\n","\n","test_dataset = prepare_dataset_infer(copy.deepcopy(dataset), test_data)\n","predictions = generate_results(model_cnn, test_dataset, num_workers=2)\n","export_preds(predictions, \"test_output.txt\")\n","!python3 ../input/eval.py test_output.txt ../input/sents.answer\n","\n","#Accuracy= 0.8980328763672244 - 2 epochs, lr: 0.01, unk: 0.01->0.50\n","#Accuracy= 0.9002792181890706 - 2 epochs, lr: 0.005, unk: 0.05\n","#Accuracy= 0.930237440429954  - epochs=1, lr=0.01, patience=50\n","#Accuracy= 0.9404614447966746 - epochs=5, unk=0.01"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"nbformat":4,"nbformat_minor":1}