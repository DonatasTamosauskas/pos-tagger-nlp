{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "def train_model(train_file, model_file):\n",
    "    # write your code here. You can add functions as well.\n",
    "    # use torch library to save model parameters, hyperparameters, etc. to model_file\n",
    "    print('Finished...')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # make no changes here\n",
    "    train_file = sys.argv[1]\n",
    "    model_file = sys.argv[2]\n",
    "    train_model(train_file, model_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and do the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cec51b650782>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtest_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmodel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mout_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mtag_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "def tag_sentence(test_file, model_file, out_file):\n",
    "    # write your code here. You can add functions as well.\n",
    "\t\t# use torch library to load model_file\n",
    "    print('Finished...')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # make no changes here\n",
    "    test_file = sys.argv[1]\n",
    "    model_file = sys.argv[2]\n",
    "    out_file = sys.argv[3]\n",
    "    tag_sentence(test_file, model_file, out_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The network:\n",
    "1. CNN character level word embedder\n",
    "1. concatenate CNN embedding with word embedding\n",
    "1. bi-directional LSTM block, looking at a sentence\n",
    "1. fully conncected layer? (what does linear projection mean?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastprogress in /opt/conda/lib/python3.6/site-packages (0.1.21)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib) (2.8.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib) (1.1.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib) (0.10.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib) (2.4.2)\r\n",
      "Requirement already satisfied: numpy>=1.11 in /opt/conda/lib/python3.6/site-packages (from matplotlib) (1.17.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib) (41.4.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install fastprogress matplotlib\n",
    "from fastprogress import progress_bar\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "training_data = Path(\"../data/sents.train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating data input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, path, to_lower=True):\n",
    "        self.to_lower = to_lower\n",
    "        self.sentences = []\n",
    "        self.vocab = []\n",
    "        self.tags = []\n",
    "        \n",
    "        self.generate_dataset(path)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sentence_embs, tag_embs = self.transform_sentence(self.sentences[index])\n",
    "        return sentence_embs, tag_embs\n",
    "    \n",
    "    def generate_dataset(self, path):\n",
    "        with open(path, 'r') as input_file:\n",
    "            self.sentences = input_file.read().split(\"\\n\")\n",
    "            self.create_vocabs(self.sentences)\n",
    "            \n",
    "            self.vocab_size = len(self.vocab)\n",
    "            self.tag_size = len(self.tags)\n",
    "            \n",
    "            if self.sentences[-1] == \"\":\n",
    "                self.sentences.pop()\n",
    "            \n",
    "    \n",
    "    def create_vocabs(self, sentences):\n",
    "        vocab_set = set()\n",
    "        tag_set = set()\n",
    "\n",
    "        for sentence in sentences:\n",
    "            for word in sentence.split(\" \"):\n",
    "                try:\n",
    "                    word, tag = self.split_words_tag(word)\n",
    "                    vocab_set.add(word.lower() if self.to_lower else word)\n",
    "                    tag_set.add(tag)\n",
    "                except RuntimeError:\n",
    "                    print(\"Not a valid word/tag pair: \" + word)\n",
    "\n",
    "        self.vocab = list(vocab_set)\n",
    "        self.tags = list(tag_set)\n",
    "            \n",
    "    def transform_sentence(self, sentence):\n",
    "        numeric_sent = []\n",
    "        tags = []\n",
    "\n",
    "        for word_tag in sentence.split(\" \"):\n",
    "            try:\n",
    "                word, tag = self.split_words_tag(word_tag)\n",
    "                tag_id = self.tags.index(tag)\n",
    "                word_id = self.vocab.index(word.lower() if self.to_lower else word)\n",
    "\n",
    "            except RuntimeError:\n",
    "                print(\"Not a valid word/tag pair: \" + word_tag)\n",
    "            except ValueError:\n",
    "                print(\"Word not in the vocab: \" + word_tag)\n",
    "                # The id of an unknown word\n",
    "                word_id = len(self.vocab)\n",
    "                tag_id = len(self.tags)\n",
    "\n",
    "            numeric_sent.append(word_id)\n",
    "            tags.append(tag_id)\n",
    "\n",
    "        return torch.tensor(numeric_sent), torch.tensor(tags)\n",
    "\n",
    "    @staticmethod\n",
    "    def split_words_tag(word):\n",
    "        words_tag = word.split(\"/\")\n",
    "        \n",
    "        if len(words_tag) < 2: \n",
    "            raise RuntimeError(\"Not a valid word/tag pair:\" + word)\n",
    "            \n",
    "        tag = words_tag.pop()\n",
    "        word = \"/\".join(words_tag)\n",
    "        \n",
    "        return word, tag\n",
    "                \n",
    "    def decode_sentence(self, sentence):\n",
    "        return \" \".join([self.vocab[word.item()] for word in sentence.view(-1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a valid word/tag pair: \n",
      "CPU times: user 1.47 s, sys: 31.7 ms, total: 1.5 s\n",
      "Wall time: 1.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset = Dataset(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 1\n",
    "num_workers = 4\n",
    "\n",
    "\n",
    "pos_dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial simple model implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposed plan:\n",
    "1. Begin with word-level LSTM (check for an example in forum)\n",
    "2. Make it bi-directional\n",
    "3. Add character-level CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a new notebook: https://polynote.org/docs/01-installation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipelineTestModel(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dims, output_dims):\n",
    "        super(PipelineTestModel, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.emb_dims = emb_dims\n",
    "        self.output_dims = output_dims\n",
    "        \n",
    "        self.emb = nn.Embedding(self.vocab_size, self.emb_dims)\n",
    "        self.fc = nn.LSTM(self.emb_dims, self.output_dims)\n",
    "        \n",
    "    def forward(self, sentence):\n",
    "        print(sentence.shape)\n",
    "        emb = self.emb(sentence)\n",
    "        print(emb.shape)\n",
    "#         tags = F.softmax(self.fc(emb), dim=self.output_dims)\n",
    "        tags = self.fc(emb.view(len(sentence), 1, -1))\n",
    "        print(tags.shape)\n",
    "        return tags    \n",
    "    \n",
    "    \n",
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence[-1]), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence[-1]), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dims = 128\n",
    "hidden_dims = 64\n",
    "vocab_size = dataset.vocab_size\n",
    "tagset_size = dataset.tag_size\n",
    "\n",
    "model = LSTMTagger(embedding_dims, hidden_dims, vocab_size, tagset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 49, 45])   torch.Size([1, 49])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (1) to match target batch_size (49).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ed043e2312db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1834\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1835\u001b[0m         raise ValueError('Expected input batch_size ({}) to match target batch_size ({}).'\n\u001b[0;32m-> 1836\u001b[0;31m                          .format(input.size(0), target.size(0)))\n\u001b[0m\u001b[1;32m   1837\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (1) to match target batch_size (49)."
     ]
    }
   ],
   "source": [
    "class TestEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden, out_dims):\n",
    "        super(TestEmbedding, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.emb_size = emb_size\n",
    "        self.hidden = hidden\n",
    "        self.out_dims = out_dims\n",
    "        \n",
    "        self.emb = nn.Embedding(self.vocab_size, self.emb_size)\n",
    "        self.lstm = nn.LSTM(self.emb_size, self.hidden)\n",
    "        self.fc = nn.Linear(self.hidden, self.out_dims)\n",
    "        \n",
    "    def forward(self, sentence):\n",
    "        embeddings = self.emb(sentence)\n",
    "        hidden, _ = self.lstm(embeddings)\n",
    "#         return hidden.view(len(sentence[-1]), 1, -1)\n",
    "        return self.fc(hidden.view(len(sentence[-1]), 1, -1)).view(1, len(sentence[-1]), -1)\n",
    "    \n",
    "test_model = TestEmbedding(dataset.vocab_size, 128, 10, dataset.tag_size)\n",
    "loss_func = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "x, y = next(iter(pos_dataloader))\n",
    "\n",
    "pred = test_model(x)\n",
    "test_model.zero_grad()\n",
    "\n",
    "print(pred.shape, \" \", y.shape)\n",
    "\n",
    "loss = loss_func(pred, y.view(-1))\n",
    "\n",
    "\n",
    "# y1, (y2, y3) = test_model(x)\n",
    "# print(y1.shape)\n",
    "# print(y2.shape)\n",
    "# print(y3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-de191f53719d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pad the input so that it is possible to use mini-batches\n",
    "\n",
    "- Padding | https://discuss.pytorch.org/t/understanding-pack-padded-sequence-and-pad-packed-sequence/4099\n",
    "- Padding | https://discuss.pytorch.org/t/simple-working-example-how-to-use-packing-for-variable-length-sequence-inputs-for-rnn/2120\n",
    "\n",
    "## The padding needs to take place in the DataLoader\n",
    "- Most likely will need to use sampler & collate_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 55s, sys: 18.6 s, total: 3min 14s\n",
      "Wall time: 5min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "gpu = torch.device(\"cuda\")\n",
    "\n",
    "model = LSTMTagger(embedding_dims, hidden_dims, vocab_size, tagset_size)\n",
    "loss_func = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "tag_size = dataset.tag_size\n",
    "losses = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "model.to(gpu)\n",
    "\n",
    "for epoch in progress_bar(range(epochs)):\n",
    "    for x, y in pos_dataloader:\n",
    "        model.zero_grad()\n",
    "        \n",
    "        x, y = x.to(gpu), y.to(gpu)\n",
    "\n",
    "        pred = model(x)\n",
    "        loss = loss_func(pred.view(-1, tag_size), y.view(-1))\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1484832763671875e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "print(min(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = torch.device(\"cuda\")\n",
    "# gpu_model = model.to(gpu)\n",
    "\n",
    "\n",
    "stop_range = 1\n",
    "i = 0\n",
    "epochs = 1\n",
    "\n",
    "preds = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for x, y in progress_bar(pos_dataloader):\n",
    "        if i > stop_range: break\n",
    "        i += 1\n",
    "        \n",
    "#         x_gpu, y_gpu = x.to(gpu), y.to(gpu)\n",
    "#         preds.append(model(x))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([31, 41, 46, 18, 18, 11, 22, 24, 21, 43, 18, 23, 33, 32, 42, 41,  6, 10,\n",
       "         10, 26,  1, 21, 13, 10, 42, 19, 42, 28, 24, 35, 28, 46, 37, 32,  5, 16,\n",
       "         48, 13, 35, 42, 29, 43, 28,  5, 23]),\n",
       " tensor([0, 0, 4, 0, 2, 2, 4, 1, 0, 4, 0, 3, 4, 1, 0, 0, 3, 4, 0, 2, 1, 4, 1, 4,\n",
       "         3, 2, 1, 3, 1, 2, 2, 3, 0, 2, 1, 4, 1, 4, 4, 1, 0, 4, 0, 3, 3]),\n",
       " tensor([ 8, 19, 15,  0,  2,  9,  9, 15, 13, 19,  4,  3,  0, 14, 13, 15,  7,  9,\n",
       "          6,  8,  5,  1,  6, 13,  9,  0,  1,  6,  1, 14, 11, 15, 18,  2, 13,  6,\n",
       "          2, 10, 19,  1, 14, 15,  9,  6,  4]),\n",
       " tensor([ 4,  7,  1,  5, 10,  7, 10,  2,  1,  7,  3,  9, 10,  2,  6,  9,  2,  3,\n",
       "          6, 11,  2, 11,  1,  1,  6,  5,  2,  2,  2,  0,  7,  2,  6, 10,  2, 10,\n",
       "          8, 10,  2,  8,  6,  5,  4,  6,  5]),\n",
       " tensor([10,  7, 15, 27, 24, 12,  1,  8, 15, 28, 13, 13, 23, 16,  7, 22, 16, 10,\n",
       "          6, 13, 25, 14, 11, 15, 12, 11, 27,  1, 25, 21, 21, 16,  7,  1,  5, 11,\n",
       "         28, 18, 28, 20, 10, 12, 26, 26,  9]),\n",
       " tensor([ 8, 14,  2,  3,  7,  9, 14, 13,  1, 10,  2,  2,  1,  7, 12,  6,  1,  6,\n",
       "         11, 13,  5, 10,  3,  2,  0,  6, 12,  4,  8, 11,  0, 13,  9, 12,  4,  2,\n",
       "         14,  7, 14, 13,  6,  0,  4,  0,  7]),\n",
       " tensor([7, 8, 2, 4, 1, 7, 8, 5, 4, 8, 4, 4, 2, 1, 0, 0, 1, 5, 6, 5, 6, 2, 5, 6,\n",
       "         4, 8, 4, 1, 1, 6, 7, 5, 3, 0, 3, 2, 2, 1, 8, 3, 5, 8, 6, 3, 1]),\n",
       " tensor([3, 5, 1, 1, 6, 6, 7, 5, 0, 7, 2, 1, 7, 1, 0, 4, 0, 5, 6, 6, 2, 4, 3, 1,\n",
       "         7, 7, 6, 2, 2, 4, 4, 0, 6, 6, 6, 7, 2, 7, 3, 6, 2, 3, 1, 2, 3]),\n",
       " tensor([ 1, 13, 15,  4,  4, 10, 14,  6,  7, 16,  0,  2,  8,  4,  7, 11,  5, 12,\n",
       "          9,  9,  6,  5, 16, 12,  7,  5,  5, 10,  4, 14,  0, 13, 10,  4, 10, 16,\n",
       "         16, 12, 16,  8,  2,  0,  9,  4, 10]),\n",
       " tensor([ 0, 18, 22,  8,  0, 15,  5, 12,  8, 24,  7,  2, 19,  4, 16,  8,  8, 20,\n",
       "          7, 22, 12, 17, 20,  5, 20, 11, 13, 13, 13,  4, 13, 23,  7, 12, 19,  5,\n",
       "         12,  5, 24, 23, 11,  1, 20, 21,  0]),\n",
       " tensor([26, 23, 18,  5, 18,  3, 10, 30, 10, 32, 10, 24, 27,  6, 22, 24, 18, 32,\n",
       "         16, 30,  6, 14, 17,  8, 16, 12, 21,  2,  5, 13, 31, 31, 16, 29, 15,  6,\n",
       "         32,  3, 32, 27, 19,  3, 10, 16, 20]),\n",
       " tensor([18, 25, 28,  3,  3, 35, 36, 10, 20, 36, 12, 16, 34, 32, 14, 11, 16, 35,\n",
       "          8, 31, 20, 13, 34, 13, 29, 34, 34, 36, 23, 14, 11, 15, 35,  2, 10, 33,\n",
       "         14, 15, 36, 18, 24, 21, 16,  3, 18]),\n",
       " tensor([ 1,  8, 15, 10, 15,  8,  3, 11,  6, 16,  1, 11, 13, 14,  7,  7, 14, 12,\n",
       "          6,  3, 12,  5,  5,  3,  8, 10,  6,  4,  4,  8, 11, 11, 10,  3, 14,  8,\n",
       "         13,  3, 16, 13,  9,  3,  6, 10,  1]),\n",
       " tensor([47, 42, 38, 24, 13, 38, 37, 17, 32,  8, 16,  5, 19, 37, 43, 42,  5, 34,\n",
       "         16, 29, 26, 15, 35, 46, 34, 41, 22, 24, 40, 42, 12, 23, 18, 26,  6, 40,\n",
       "         37, 33, 47, 19, 22,  6,  5,  3, 11]),\n",
       " tensor([40, 13, 40, 18, 39, 20, 43, 15, 33,  3, 40, 25, 28, 18, 12, 25, 21, 41,\n",
       "         24, 16, 14,  8, 34, 30, 19, 21, 21, 30, 14,  8, 30,  5, 10, 17,  4, 43,\n",
       "         13, 30, 27, 28, 21,  7, 23,  5, 20]),\n",
       " tensor([ 7, 11, 12,  3,  6,  5, 11,  7,  4, 11,  5, 12, 11,  2,  2,  4,  0,  5,\n",
       "         12, 12,  1,  2, 12, 10,  4,  4,  0,  5,  4,  2,  7,  1,  5,  2,  1,  2,\n",
       "         11,  8, 11,  9,  7,  9,  5,  6,  6]),\n",
       " tensor([ 5,  7,  4, 13,  3, 22, 24, 18, 11, 29,  0,  6, 20, 28, 24,  7, 26, 21,\n",
       "          9, 26,  9,  4, 16,  4, 16, 14, 20, 11, 25, 14, 11, 11, 17, 28, 15, 13,\n",
       "         29, 12, 29,  8, 28,  7, 21, 17, 26]),\n",
       " tensor([12, 17, 15,  2,  5, 11, 17, 14, 11, 17, 13, 12,  5,  2,  6, 12,  4, 17,\n",
       "          1, 14,  3,  5, 17,  3, 12, 16, 13, 15,  2,  1,  2,  2,  4, 13,  4, 17,\n",
       "         17,  9, 17, 14, 11, 16,  8,  5,  8]),\n",
       " tensor([24, 36,  3, 14,  2, 34, 18,  6, 32, 28, 42, 14,  6, 22, 36, 40, 17,  6,\n",
       "         41, 16,  5, 27, 26,  2, 38, 19, 39, 36, 41, 19, 39, 14, 37, 43, 37, 28,\n",
       "         12,  4, 45, 11, 39, 24, 10, 21, 26]),\n",
       " tensor([ 1, 22, 19, 11, 17, 14, 34,  3, 26, 19, 14, 22,  4,  0, 18, 30, 13, 29,\n",
       "         32,  5, 22, 33, 33, 17,  2, 34,  4, 18, 22,  9,  7,  5,  3,  2,  4, 33,\n",
       "         27, 13, 34,  5, 23, 20, 29, 24, 34]),\n",
       " tensor([12,  3,  6,  4,  7,  7, 10,  4,  4,  3, 14,  4, 14, 12,  1,  4,  5, 14,\n",
       "          3,  8, 13, 13, 13,  8, 12,  4,  9,  9,  2,  0,  4,  2,  2,  8,  2, 14,\n",
       "          5,  0, 14, 11, 12, 12, 14,  2, 14]),\n",
       " tensor([4, 8, 7, 0, 4, 1, 8, 1, 2, 8, 2, 8, 8, 6, 6, 5, 7, 1, 2, 2, 3, 7, 1, 6,\n",
       "         1, 4, 7, 7, 3, 3, 7, 7, 0, 6, 4, 8, 3, 8, 8, 2, 4, 5, 0, 5, 2]),\n",
       " tensor([29, 46, 31, 31,  5, 23,  6, 39,  3, 43, 27, 25,  1, 13, 39, 24,  1, 32,\n",
       "         35, 38, 34, 33, 10, 26, 19, 31,  2, 30, 39, 43, 44, 38, 38, 10,  5, 20,\n",
       "         46, 33, 46, 36,  2, 13, 20, 10, 25]),\n",
       " tensor([25, 22, 25, 47, 17,  9,  3, 40,  4, 49, 24, 46, 40,  2, 44, 36,  2,  8,\n",
       "         13, 35, 35, 13,  8, 33, 22, 11, 25, 27, 25, 12, 21, 19, 32,  5, 29, 46,\n",
       "          3,  5, 39, 31, 25,  4, 46, 11, 27]),\n",
       " tensor([13, 17,  5, 16, 13, 11,  0,  6,  7, 17,  2,  6, 17,  5,  9,  7, 12,  2,\n",
       "          2, 12, 13, 11, 11,  9,  9,  2, 14,  8,  8,  2,  7,  6,  9,  5,  6, 17,\n",
       "          3,  1, 17, 15, 14,  3, 15, 12,  4]),\n",
       " tensor([5, 9, 0, 2, 7, 1, 3, 3, 8, 9, 9, 2, 9, 6, 1, 8, 6, 9, 7, 7, 6, 0, 4, 8,\n",
       "         4, 4, 3, 3, 3, 0, 8, 1, 1, 0, 1, 4, 8, 0, 9, 5, 3, 8, 6, 2, 8]),\n",
       " tensor([10, 22, 14,  6,  1,  4, 23, 16,  8, 23, 11, 13, 23, 17, 20, 13, 14, 10,\n",
       "         21, 21, 22, 22, 22,  1, 10, 23,  8,  5,  3, 17,  3,  3,  2, 14, 17, 22,\n",
       "          6,  0, 23, 17, 20, 13, 10,  2, 23]),\n",
       " tensor([16, 13,  2, 14,  2,  6, 18, 13,  9, 11,  1, 15, 18,  0,  9, 15, 11,  6,\n",
       "         11,  3, 17, 17, 17,  3, 16, 13,  7,  4,  4,  0,  9, 10, 14,  3, 10, 18,\n",
       "          8,  6, 18, 10, 16, 16, 11, 17, 18]),\n",
       " tensor([20, 17, 20,  5, 12,  7, 10, 15, 13,  5,  8,  2, 21, 10,  5, 11, 20,  5,\n",
       "         20, 20, 20, 18, 21, 10,  7,  8, 19,  1, 15, 10, 13, 13, 18, 11, 12,  0,\n",
       "         14, 10, 21, 13, 14,  7,  5, 12, 19]),\n",
       " tensor([29, 31, 32, 17, 15, 11,  9, 24,  3, 21,  0, 29, 33, 20, 22, 23, 16, 20,\n",
       "         24, 34, 11, 19, 25, 20, 18,  7,  2,  0, 22, 13,  3, 31, 27,  5, 20,  7,\n",
       "         33, 28, 33, 31,  5,  4, 22, 17, 15]),\n",
       " tensor([25, 36, 38, 38, 25, 25, 24, 14, 32, 30, 33, 15, 24, 12, 32, 13,  6,  0,\n",
       "         18, 21, 23, 38, 23, 27, 12, 35, 21, 29, 34, 12, 33, 33, 34, 25,  5, 39,\n",
       "         20, 37,  1, 17, 26, 32, 15, 26, 15]),\n",
       " tensor([16, 12, 19, 19,  2,  5, 21, 11,  1, 21,  0, 16,  4,  4,  2, 16, 15, 14,\n",
       "         12, 15, 20,  4, 14,  4, 14, 12,  8,  8, 11, 13,  8,  8, 10,  4, 13, 10,\n",
       "          8,  9, 21, 13, 19,  6, 15,  3,  1]),\n",
       " tensor([ 5,  3,  5, 10, 12, 19,  9,  5, 16, 20,  3,  4, 10, 15,  1, 11, 15, 20,\n",
       "          2, 15,  5,  3,  5,  1, 15, 17, 13, 19,  1,  9, 17, 13, 19, 12, 13,  2,\n",
       "         20, 19, 20,  5, 16, 17,  4, 16, 14]),\n",
       " tensor([15,  8,  6, 11, 11,  3,  1, 10, 15,  4, 15, 14,  1,  7,  5, 14,  6, 15,\n",
       "          0, 10,  6,  4, 17,  8, 15,  3, 16,  4, 11,  5, 10,  8,  8, 11,  8,  6,\n",
       "         10,  5, 17,  9, 15, 15, 14, 11, 16]),\n",
       " tensor([20,  9, 13,  4, 17, 12, 17,  5,  4,  8,  3,  8, 22, 16,  1,  2,  9,  4,\n",
       "          3, 17,  9, 21, 21,  5, 20, 12, 14,  2,  3,  0, 10, 10,  1, 17, 13, 22,\n",
       "         22,  0, 22, 10, 14, 20,  9, 21, 22]),\n",
       " tensor([16,  9, 16,  8,  7,  1, 28,  3,  9, 28, 12, 15,  5, 20,  1, 15, 20,  5,\n",
       "          4, 19,  7, 13, 21,  9,  1,  5, 19, 21, 21,  0,  3, 22, 24, 16,  4, 14,\n",
       "         20, 24, 28,  8,  1, 15,  5, 21, 10]),\n",
       " tensor([22, 32,  4, 11,  0, 17, 32, 24,  6, 32,  9, 18, 28,  0, 14, 23, 18, 23,\n",
       "         27, 25, 10,  2,  9, 25, 23,  3,  7, 25, 14, 28,  8, 12, 25,  0,  3, 26,\n",
       "         32, 23, 32, 28,  2, 30, 18, 12,  7]),\n",
       " tensor([13, 18,  9, 16, 11, 17, 13,  3, 16, 18, 15, 10,  3, 14,  8, 10, 17, 12,\n",
       "         15,  6,  7,  9,  1, 13, 16, 16,  5, 15,  6,  6,  6,  6, 15,  8,  4, 13,\n",
       "         18, 13,  9,  3,  5, 10, 13,  1, 12]),\n",
       " tensor([ 0,  4, 13,  1,  7, 16, 12, 11, 10, 17, 13,  6, 17,  8, 16,  9, 15,  5,\n",
       "          0,  2, 16,  7, 14, 15, 14,  3, 11, 13,  4,  7, 11,  8, 13, 16, 14,  2,\n",
       "         17, 15, 17, 11, 16, 14,  1,  7, 17]),\n",
       " tensor([1, 2, 6, 1, 6, 8, 9, 4, 2, 9, 0, 1, 9, 7, 4, 4, 7, 8, 7, 8, 2, 7, 2, 0,\n",
       "         0, 3, 8, 2, 2, 6, 8, 3, 5, 6, 5, 9, 9, 6, 9, 3, 5, 4, 8, 6, 9]),\n",
       " tensor([30, 25, 21, 20, 31, 17,  1, 27, 34, 35, 29,  9, 22,  1,  5, 28, 14, 12,\n",
       "         11,  4, 25, 26, 35, 21, 17, 23, 14, 26, 26, 25, 12, 19, 18, 31, 22, 20,\n",
       "         30, 19, 35, 22, 17, 17, 12, 26, 17]),\n",
       " tensor([ 9, 22,  4,  7,  1,  6,  9, 25,  3, 26,  9, 23, 19,  1, 14, 23,  2,  6,\n",
       "          9,  5, 22,  4,  9, 21, 15, 19, 12,  5, 15, 17,  6,  8, 12, 24, 19,  4,\n",
       "          1,  1, 26,  8, 15, 23,  6, 18, 18]),\n",
       " tensor([ 1,  6,  8,  3,  7, 19,  0, 19,  3, 21,  1,  4, 21,  7, 19, 16,  8, 18,\n",
       "         11, 11,  1, 15,  9,  0,  3, 21,  8, 11, 15, 15, 17, 18, 19,  0, 13,  6,\n",
       "          7,  0, 17, 19, 12, 12, 20,  2,  8]),\n",
       " tensor([11, 20, 12,  6,  3,  4, 12, 19,  6, 20,  1, 19, 20, 12, 15, 10, 11, 13,\n",
       "          1,  7, 13, 15,  0, 16,  7,  4,  6,  7,  1,  3,  4,  5,  2, 13,  2, 17,\n",
       "         20, 11, 20,  0, 13, 10,  4,  2, 14]),\n",
       " tensor([10, 25, 14, 13,  0, 21, 25, 12, 18, 25, 24, 10, 12, 18,  4, 10, 19, 23,\n",
       "         24, 18, 12,  6, 24, 23,  9,  4, 19,  1,  3,  0,  2, 18,  4,  0, 20,  1,\n",
       "         25,  9, 25, 12, 11, 10, 24,  9, 23]),\n",
       " tensor([ 3, 10, 19, 17, 17,  4, 18,  6, 15, 22, 10, 11,  8, 17, 16, 11, 15, 21,\n",
       "          6,  1, 18, 17, 22, 19,  4,  1, 14,  4,  4, 16,  1,  9, 12, 19,  8, 19,\n",
       "         17, 17, 22,  8, 20,  2, 18, 16, 13]),\n",
       " tensor([29, 23,  3,  2,  2, 24,  5, 23,  8, 33,  3, 21, 13, 14, 10, 21, 24,  9,\n",
       "         22,  1, 17, 10, 19,  5,  3,  9, 11, 18, 24, 25, 23, 25, 30, 13, 10, 26,\n",
       "          2, 14, 33, 21,  8,  4,  9,  8, 28]),\n",
       " tensor([17, 16, 17, 21,  5,  3, 13, 20,  6, 22, 13, 16, 18,  6,  5, 15,  4,  7,\n",
       "          6, 21, 16, 13,  1,  0,  3,  9, 19,  2,  2,  9, 21,  9,  4,  0, 11,  2,\n",
       "         22, 22,  2, 18, 12, 11, 21,  1, 17]),\n",
       " tensor([ 4,  3, 22,  8,  8, 25,  0, 31, 26, 19,  2, 12, 21,  0,  8,  4, 29, 25,\n",
       "         27, 11, 22, 26, 27, 27,  6, 23,  5, 22, 24, 10,  3,  8, 25, 21, 10, 22,\n",
       "          0,  0, 32, 10, 23,  4, 25,  8, 18]),\n",
       " tensor([ 5,  2, 17,  8, 19, 18,  3, 17, 13, 20, 18, 11,  4, 19, 13, 11, 16,  2,\n",
       "          9, 19,  4,  2,  2, 19, 13,  4, 17, 10, 14,  0,  1, 12, 13,  4, 17, 20,\n",
       "          6,  0, 20, 11, 15,  5, 19, 10,  4]),\n",
       " tensor([ 9,  6, 14, 23, 15, 10, 28, 17, 12,  2, 11, 24, 10, 27, 17, 24, 21,  1,\n",
       "         15, 12,  6, 13, 23, 15, 17, 14, 20, 21, 23,  6, 23, 23, 21,  4, 20, 11,\n",
       "         26, 21, 28, 17, 17,  7, 21,  1, 27]),\n",
       " tensor([ 3, 23, 20, 20,  8, 10, 19, 16,  5,  1,  2, 15, 18, 15, 17, 14, 19, 13,\n",
       "          7, 19,  2,  7, 20, 15,  1,  4,  9, 19,  0, 21,  3,  3, 19, 16,  7, 23,\n",
       "         16, 20, 23, 18, 10, 15, 13, 13, 13]),\n",
       " tensor([27,  2, 22,  4, 10, 31, 10, 19, 18,  4,  3, 25, 21, 28, 35, 25, 28, 19,\n",
       "         42,  6, 12,  5,  5,  1, 39, 41, 42, 18, 18,  5, 32, 32,  2,  1, 37,  2,\n",
       "          8, 35,  5, 41, 27, 27, 17, 38, 14]),\n",
       " tensor([ 7,  9,  2,  2,  7,  0,  5,  8,  9,  2, 10,  6, 10,  9,  4,  0,  1,  5,\n",
       "          7,  2,  8,  3,  3,  1,  1, 10,  0,  5,  9,  3,  0,  3,  9,  8,  3, 10,\n",
       "          0,  6,  3,  8,  9,  6,  7,  3,  9]),\n",
       " tensor([ 5, 32, 24, 36, 23, 27,  7, 29,  3, 30,  4, 36, 12,  7,  9,  2, 34, 29,\n",
       "         26, 42, 40, 40,  5,  9,  1, 27, 34, 11, 38, 31, 32, 31, 29,  6, 39, 38,\n",
       "          7,  7, 10, 26, 38,  3, 11, 40, 28]),\n",
       " tensor([44, 17, 54, 21, 26, 52,  9, 23,  4,  5, 43, 40, 37, 28,  4, 24, 28, 50,\n",
       "         47, 44, 17,  8, 21, 17, 54, 17, 29, 12, 12, 22, 29,  4, 42,  2, 15, 12,\n",
       "         57, 21,  5, 22, 11, 32, 40, 17, 54]),\n",
       " tensor([ 3, 21, 12, 21,  6, 10, 10,  7, 22, 12,  3, 11, 22, 19,  9, 18, 11, 18,\n",
       "          3,  6,  3, 10, 19,  2,  6, 22,  2, 18, 21,  1,  6,  6,  6,  8, 10, 22,\n",
       "         14, 14, 13, 21,  5, 13, 17, 19, 11]),\n",
       " tensor([16, 10, 13, 10,  4, 13, 17,  1, 16, 17, 11,  8,  2, 14, 14,  8, 16,  3,\n",
       "          6,  6,  4, 10, 11,  1, 10, 11, 13, 13,  4,  4,  6, 16, 10,  4, 15,  6,\n",
       "         17, 17, 17, 15,  5, 16, 12,  0,  8]),\n",
       " tensor([ 6,  4, 10,  9,  6,  1, 11, 10,  0, 11,  1,  6,  7,  8,  4,  6,  3, 11,\n",
       "          2, 10,  6,  1, 11,  2,  0,  9,  7, 11,  0,  7, 10,  7,  3,  4,  7, 11,\n",
       "          2,  2, 11,  7,  0,  4, 11,  8, 11]),\n",
       " tensor([13, 20, 14,  8, 12, 15, 18, 15,  5, 20, 12, 14, 11,  4, 16,  8,  6, 14,\n",
       "         12, 14, 12,  1, 12,  4,  0, 11, 17,  2, 17,  0,  2,  5, 19,  4,  5,  6,\n",
       "         20,  4, 20, 15, 17, 13, 14, 19, 17]),\n",
       " tensor([21,  3, 15,  1, 21, 10, 16,  7, 12, 22, 11, 18, 22, 16, 10,  6, 13, 13,\n",
       "          6, 20,  2, 16, 13,  6, 15,  1, 20,  1, 10,  3, 11,  3, 11, 11, 18,  4,\n",
       "         13, 13, 22,  7, 16,  6, 20, 21, 15]),\n",
       " tensor([46, 25, 56, 56,  8, 47,  5, 39, 47, 34, 52, 27, 36, 56, 10, 35, 12, 46,\n",
       "         11, 21,  4, 52, 52, 56, 47, 52, 39, 52, 51,  2, 30, 50,  2,  8, 11,  6,\n",
       "         14, 43, 10, 30, 46, 35, 27, 33, 27]),\n",
       " tensor([26, 32, 18, 12, 14, 28,  7,  1,  1, 32, 18, 23, 32,  1,  1, 23,  5, 27,\n",
       "         15,  8, 15,  6, 31, 28,  0, 12, 30, 19, 19,  2, 30, 30, 20, 27, 29, 19,\n",
       "         20, 13, 32, 29,  1, 26, 17, 14, 25]),\n",
       " tensor([14, 35, 12, 17, 29,  4, 33, 27, 15, 18, 12, 25, 20, 34, 15, 28, 34, 15,\n",
       "         35,  5, 17, 39, 40, 34,  7, 40,  5, 32, 22,  9, 27, 29, 20, 16,  3, 40,\n",
       "         35, 37, 35, 25, 14, 14, 31, 22,  2]),\n",
       " tensor([22, 30, 20, 20, 13, 26,  7, 26, 28, 14,  8, 23,  0, 17, 28, 21, 23, 17,\n",
       "          7, 11,  9, 18, 27, 12, 30, 13, 29,  3,  4,  9,  2,  2,  3,  5,  0, 30,\n",
       "          2,  3, 30, 28, 19, 11, 23, 13, 11]),\n",
       " tensor([ 9, 12,  2, 13,  3, 14, 22, 15, 21, 22,  5, 11, 12, 13, 15, 16, 18,  4,\n",
       "         18,  2, 13,  1, 18, 12,  4, 20,  7,  7,  0, 11,  7, 19, 15,  2, 18,  2,\n",
       "          7,  6, 22, 17,  0, 12,  6, 12,  4]),\n",
       " tensor([13, 37, 45, 28, 35, 48, 49,  4, 22, 49,  5, 29, 19, 12, 48, 16, 13, 49,\n",
       "          1, 17,  0,  4,  2, 38, 34, 24,  4, 26,  8, 25,  9, 34, 48, 35, 43, 26,\n",
       "          9, 25, 49, 30, 33, 38, 18,  2, 21]),\n",
       " tensor([2, 6, 5, 4, 0, 4, 6, 1, 3, 6, 4, 1, 6, 1, 3, 1, 2, 6, 3, 5, 0, 2, 6, 4,\n",
       "         6, 6, 1, 5, 0, 2, 1, 1, 0, 0, 0, 6, 6, 2, 3, 5, 0, 6, 4, 0, 1]),\n",
       " tensor([ 9, 12, 21, 33, 23, 18, 37, 34, 24, 45,  4, 20, 19, 16, 44, 17, 11,  7,\n",
       "         26, 18, 35,  7, 27,  3,  1, 45, 21,  8, 12,  3, 39, 24, 13, 32, 13, 12,\n",
       "         29, 10,  7, 20, 29, 17, 38, 13, 27]),\n",
       " tensor([38, 15, 29, 29, 43, 30,  2, 11, 37, 30, 28, 34, 32, 35,  8, 34, 49, 18,\n",
       "         10, 51, 23,  1, 44, 14, 30, 25, 49, 46, 24, 10, 11, 15, 39,  5, 40, 50,\n",
       "         21, 29, 50, 33,  3,  4, 30, 41, 24]),\n",
       " tensor([ 9, 12, 22,  5,  3, 21, 32, 31, 16, 32, 19, 18, 31,  1, 12,  8, 29, 32,\n",
       "          5, 12, 14, 16, 30, 24, 27, 32, 30,  5,  1,  4, 15, 17, 21, 14,  2, 32,\n",
       "         32, 11, 32,  9,  1,  9,  7,  4, 13]),\n",
       " tensor([39,  6, 18, 13,  9,  4,  4, 29, 23, 42,  6, 13, 34, 20, 42, 25, 47,  7,\n",
       "         26, 16, 18, 31, 20, 19, 31, 40, 47, 16, 10, 47, 36, 28, 16, 33,  1, 28,\n",
       "         36, 38, 23, 46, 31, 44, 21, 38, 44]),\n",
       " tensor([19, 21, 17,  7, 14, 12, 24, 11, 24, 24, 24, 22,  9, 20, 13, 18,  0, 19,\n",
       "         19,  3,  7, 12,  8, 19,  4,  9,  2, 12, 15, 21, 12,  4,  9,  7, 14, 15,\n",
       "         24,  4, 24,  3, 14, 22,  5, 14, 10]),\n",
       " tensor([13, 26, 33, 41, 14,  2, 16,  1,  3,  7, 26, 39, 37, 16, 17, 31, 32,  4,\n",
       "         26, 36, 22,  7, 40, 10, 38, 13, 29, 40, 12, 14, 19, 13, 41,  9, 37, 42,\n",
       "         34, 42,  3, 37, 20, 18,  4, 39,  2]),\n",
       " tensor([ 1,  1,  5,  0,  3,  4,  1,  9,  5, 11,  2,  0,  8,  3,  3,  7,  0, 11,\n",
       "          6,  6,  6, 10, 11,  5,  2, 11, 10,  1,  2,  8,  2,  7,  1,  3,  9, 11,\n",
       "          5,  1, 11, 10, 11,  6,  0,  6,  0]),\n",
       " tensor([ 0, 14,  6,  8, 12,  1,  2,  9, 14, 14,  3,  7,  4,  6, 10, 11,  2, 10,\n",
       "         13, 10, 12,  1, 13,  3,  1,  4,  8, 13, 14,  5, 10,  4,  7,  5,  8, 13,\n",
       "          7,  5,  5,  2,  0,  2, 13,  5,  6]),\n",
       " tensor([7, 8, 6, 4, 0, 1, 8, 1, 1, 8, 4, 6, 5, 3, 2, 8, 3, 8, 4, 7, 0, 2, 4, 3,\n",
       "         1, 2, 5, 4, 8, 7, 6, 6, 4, 1, 3, 3, 3, 7, 6, 1, 6, 3, 8, 6, 7]),\n",
       " tensor([50, 28, 14,  0, 46, 44, 26, 48, 22, 52, 37, 38, 41, 43,  4,  6, 43, 44,\n",
       "         37, 30, 17, 18, 49,  7, 10, 36,  4, 10, 49, 47,  3, 32, 47, 44, 35, 52,\n",
       "         43, 26, 52, 48,  8, 29, 38, 36, 12]),\n",
       " tensor([11, 17, 14, 10, 13, 15,  5, 12, 14, 16,  9,  9, 13, 15, 15,  3,  5, 16,\n",
       "          9,  8,  7,  3, 17,  8, 12,  2,  5,  4,  1, 17,  3, 10, 10, 13, 15,  1,\n",
       "          4, 17, 16, 15,  1, 15, 12,  2, 12]),\n",
       " tensor([17, 25,  9, 30, 20,  9, 23, 20, 18, 21,  2, 27, 11, 23, 14, 29, 22, 28,\n",
       "         20, 26, 15,  7,  9, 26, 11, 13, 17,  8, 15,  6, 30,  3, 13, 24,  4,  1,\n",
       "         23, 29, 31, 26, 16, 25, 21, 11,  8]),\n",
       " tensor([ 9,  4,  5, 46, 28, 19, 25,  3,  7, 48, 26, 22, 40, 31, 11, 22, 45,  3,\n",
       "         16, 30, 29, 45, 30,  5,  1, 27, 32, 45,  8, 28,  8,  8, 39,  3, 27, 25,\n",
       "         48, 45, 48,  7, 13,  4, 20, 37, 26]),\n",
       " tensor([28, 32, 28,  4,  3,  5,  6, 25, 24, 32, 28, 28, 23, 26,  5, 19, 13, 10,\n",
       "          8, 21,  4,  3, 15, 20, 15, 23, 21, 15, 18,  3, 21,  7,  2,  1,  9, 32,\n",
       "          7,  3, 32,  9, 15, 19, 10,  4, 27]),\n",
       " tensor([15, 14, 13, 14, 19,  1, 30, 25, 22, 32,  8, 15, 30, 22, 25, 15, 23, 16,\n",
       "         20, 13, 19, 27,  6,  6,  2, 28, 25, 20,  8, 19,  4, 24, 28,  2, 23,  6,\n",
       "         24, 18, 32, 30, 25,  3, 17, 19, 10]),\n",
       " tensor([3, 7, 6, 4, 2, 1, 2, 5, 7, 7, 7, 6, 4, 0, 7, 7, 2, 7, 5, 7, 3, 5, 0, 2,\n",
       "         1, 4, 4, 7, 7, 4, 7, 4, 4, 2, 4, 2, 1, 2, 4, 3, 0, 1, 7, 0, 6]),\n",
       " tensor([28, 38,  6, 25, 16, 21, 32, 26, 29, 24, 29,  4, 34, 23, 38, 28, 36, 30,\n",
       "         20,  9, 26, 21,  3, 24, 19,  8, 32,  5, 22, 16, 38, 16,  2, 33,  1, 24,\n",
       "         17, 14,  3,  8, 25, 12,  4, 23, 24]),\n",
       " tensor([0, 3, 0, 1, 0, 3, 3, 1, 3, 3, 3, 1, 2, 3, 3, 1, 2, 0, 3, 0, 0, 1, 1, 0,\n",
       "         0, 3, 2, 2, 3, 1, 3, 1, 0, 0, 3, 3, 3, 1, 0, 3, 2, 0, 3, 1, 1]),\n",
       " tensor([0, 5, 0, 3, 3, 0, 1, 0, 5, 2, 3, 4, 4, 2, 5, 1, 0, 0, 5, 0, 5, 3, 4, 0,\n",
       "         0, 1, 4, 2, 5, 3, 0, 4, 3, 0, 5, 4, 2, 1, 4, 5, 1, 1, 2, 3, 4]),\n",
       " tensor([ 6, 13,  4,  4, 25,  2, 35,  1,  1, 35, 33,  6, 24, 25, 13,  8, 28, 32,\n",
       "         16,  4,  6, 15,  2,  7, 15, 14, 22,  3,  5, 11, 22, 26, 33, 17, 14, 31,\n",
       "         22, 11, 35, 24, 21,  7,  2, 26,  9]),\n",
       " tensor([ 5, 18,  8,  7, 17,  2, 19,  2, 11, 12,  8, 10, 18,  1,  2, 15, 10,  6,\n",
       "          5, 16, 16, 15,  6,  0,  5, 12, 12,  3,  7,  4, 12,  5, 17,  8,  2,  9,\n",
       "         19, 19, 19,  4,  8, 18, 10,  9, 10]),\n",
       " tensor([ 6, 10,  1,  0,  9,  4, 10,  5,  5,  4,  0,  6, 10,  2,  3,  0,  8,  5,\n",
       "          0,  5,  9,  4,  5,  9,  5,  2,  3,  1,  1,  7,  4,  3,  4,  9,  7, 10,\n",
       "          8,  8, 10,  7,  2, 10,  9,  2,  4]),\n",
       " tensor([21, 27, 22,  4, 25, 15, 28,  8, 27, 10, 20, 20, 28, 16, 17,  4, 21, 12,\n",
       "         22, 23, 20, 16, 14, 19, 13, 15,  8,  7,  8, 16,  8,  1,  5, 17, 22, 16,\n",
       "         17,  5,  0,  8,  8, 10,  9,  1, 15]),\n",
       " tensor([ 3, 18, 11, 10, 17,  7,  6, 16,  3, 18,  3, 14, 18,  6,  7,  2, 11,  3,\n",
       "          6, 16, 17,  6, 13, 16,  3,  1, 14,  9, 17,  5, 16,  9,  9, 15, 13, 18,\n",
       "         14, 10,  8, 15,  3,  3,  8,  9, 13]),\n",
       " tensor([15,  0, 16, 10, 12,  3, 19, 18, 14, 19, 16,  5, 17,  2,  3, 16, 13, 19,\n",
       "         11, 18, 10,  0,  1, 18,  4, 12, 18,  9,  9,  2,  8,  6, 16,  3, 12,  8,\n",
       "         19, 13, 19, 18, 12,  6,  5,  1,  8]),\n",
       " tensor([ 6,  7, 15, 12, 12,  8,  5,  2,  6, 18, 12,  9,  4,  3,  4,  2,  3,  8,\n",
       "          9, 14,  5, 14, 17, 10, 17, 12,  1, 18, 17,  4,  7,  7,  1,  3,  7, 12,\n",
       "         18, 11, 18,  2, 12,  6,  1, 12, 14]),\n",
       " tensor([ 1,  8,  6,  6,  1,  6, 16,  3,  0, 16,  6,  2,  3,  9,  0, 15,  9,  2,\n",
       "         15,  1,  1, 15, 13, 13,  2, 14, 15,  6, 10, 15,  7,  4,  0,  1, 13, 11,\n",
       "          9, 14, 16,  3, 10,  3,  6,  6, 16]),\n",
       " tensor([10, 13, 15,  8, 11,  7,  1,  9,  1, 17,  8, 10, 14,  1,  9, 15,  3,  9,\n",
       "         16,  9, 13,  1,  1,  0,  5,  8, 13,  3, 12, 13, 16,  2,  4, 12, 14, 12,\n",
       "          1,  3, 17, 14,  8, 16,  6,  4, 10]),\n",
       " tensor([18, 26, 18,  9, 24, 11, 23, 20, 12, 26, 11, 16,  6,  1, 25,  8, 15,  3,\n",
       "          9, 21, 16, 11, 12, 21, 18, 12, 15, 14, 14,  6, 23,  7, 24,  3, 19, 15,\n",
       "         26,  0, 26,  6, 12,  3, 23, 12, 14]),\n",
       " tensor([45, 18, 24, 10,  3, 35, 21, 32, 14, 21, 28, 41, 29,  2, 35, 22, 20, 23,\n",
       "         45, 36, 26,  4, 19, 41, 34, 43,  7, 26, 26, 18,  8, 18, 36,  0, 16,  2,\n",
       "          2, 22, 46, 35, 30, 41, 24, 30,  7]),\n",
       " tensor([ 1, 28, 18, 27, 18, 15, 13,  2, 10, 21, 26, 11, 13, 21, 19, 20, 12, 15,\n",
       "         26, 18, 18,  5, 26,  8,  8, 27,  1, 24, 24, 13,  2, 26, 27, 18, 25, 28,\n",
       "         28, 12, 28,  2,  2, 26,  8, 22,  5]),\n",
       " tensor([ 4,  1, 19, 15, 16,  2,  8, 11, 26, 27,  2, 14, 27,  8,  3,  4,  7,  3,\n",
       "         14, 13, 22, 10,  3,  1, 12, 16, 17, 24, 24, 18, 15,  0, 26, 19,  5,  2,\n",
       "          8, 27, 27, 13, 10,  4, 24, 18, 16]),\n",
       " tensor([29, 25, 40, 28, 27, 23,  3, 24, 36, 47, 10, 37, 42,  3,  6, 26, 43, 20,\n",
       "          6, 45, 15,  6,  5,  7,  5, 42, 42,  8, 16, 34, 46, 11,  9, 14, 42, 16,\n",
       "          3, 23, 47, 32, 22, 37,  7,  6, 16])]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pred.max(0)[1] for pred in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-3715af0c1653>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/fastprogress/fastprogress.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_update\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_interrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/fastprogress/fastprogress.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_v\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_v\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0mcur_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mavg_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcur_t\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in progress_bar(range(1000000000)):\n",
    "    i = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 28 09:58:05 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 430.50       Driver Version: 430.50       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 1070    Off  | 00000000:01:00.0  On |                  N/A |\r\n",
      "|  0%   48C    P5    12W / 180W |   1436MiB /  8116MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7433], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.rand(1).to(torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
